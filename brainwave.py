# -*- coding: utf-8 -*-
"""brAInwave.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jlWRO_BzsZsuSDxavSshMWPeVfGqZz3e
"""

import numpy as np
import pandas as pd
import logging
from typing import Dict, List, Any, Tuple
from datetime import datetime
import requests
import xgboost as xgb
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import shap

logging.basicConfig(level=logging.INFO)

# API Configurations
ALPHA_VANTAGE_CONFIG = {
    "API_KEY": "40HYVDQDMF3PJD01"
}

ONDEMAND_CONFIG = {
    "API_KEY": "YVDHi9RwZsEzK0yfbdTBhZD39jNv5kvg",
    "EXTERNAL_USER_ID": "671b37db126b587457bd12b8",
    "BASE_URL": "https://api.on-demand.io/chat/v1"
}

class OnDemandClient:
    def __init__(self, config: Dict[str, str]):
        self.api_key = config["API_KEY"]
        self.external_user_id = config["EXTERNAL_USER_ID"]
        self.base_url = config["BASE_URL"]
        self.session = None

    def create_session(self):
        create_session_url = f'{self.base_url}/sessions'
        headers = {'apikey': self.api_key}
        try:
            response = requests.post(create_session_url, headers=headers)
            response.raise_for_status()
            self.session = response.json()
            return self.session
        except Exception as e:
            logging.error(f"Failed to create OnDemand session: {str(e)}")
            return None

class AlphaVantageClient:
    def __init__(self, alpha_config: Dict[str, str], ondemand_config: Dict[str, str]):
        self.api_key = alpha_config["API_KEY"]
        self.ondemand_client = OnDemandClient(ondemand_config)

    def get_stock_data(self, symbol: str) -> Dict:
        try:
            url = "https://www.alphavantage.co/query"
            params = {
                "function": "TIME_SERIES_DAILY",
                "symbol": symbol,
                "outputsize": "compact",
                "apikey": self.api_key
            }
            response = requests.get(url, params=params)
            response.raise_for_status()
            data = response.json()

            if "Time Series (Daily)" in data:
                historical_data = []
                for date, values in data["Time Series (Daily)"].items():
                    historical_data.append({
                        "date": date,
                        "open": float(values["1. open"]),
                        "high": float(values["2. high"]),
                        "low": float(values["3. low"]),
                        "close": float(values["4. close"]),
                        "volume": int(values["5. volume"])
                    })
                return {
                    "historical_data": historical_data,
                    "current_price": float(historical_data[0]["close"]),
                    "price_change": float(historical_data[0]["close"]) - float(historical_data[1]["close"])
                }
            else:
                raise ValueError("Invalid API response format")
        except Exception as e:
            logging.error(f"Failed to fetch stock data: {str(e)}")
            return {"error": str(e)}

class EnhancedXAI:
    def __init__(self, models: Dict, feature_names: List[str]):
        self.models = models
        self.feature_names = feature_names
        self.shap_explainer = shap.TreeExplainer(models['rf'])

    def explain_prediction(self, X: np.ndarray, historical_prices: pd.Series) -> Dict[str, Any]:
        instance = X[-1].reshape(1, -1)
        prediction = self.models['rf'].predict(instance)[0]
        shap_values = self.shap_explainer.shap_values(instance)

        if isinstance(shap_values, list):
            shap_values = shap_values[1] if len(shap_values) > 1 else shap_values[0]

        technical_indicators = {}
        for feature_name, impact in zip(self.feature_names, shap_values[0]):
            technical_indicators[feature_name] = float(impact)

        explanations = {
            'prediction': prediction,
            'trading_signals': self._generate_trading_signals(prediction, historical_prices.iloc[-1], shap_values[0]),
            'risk_metrics': self._calculate_risk_metrics(historical_prices),
            'technical_indicators': technical_indicators
        }
        explanations['summary'] = self.generate_summary(explanations)
        return explanations

    def _generate_trading_signals(self, prediction, current_price, feature_impacts) -> Dict[str, Any]:
        price_change_pct = (prediction - current_price) / current_price
        signal_strength = 1 if price_change_pct > 0.02 else -1 if price_change_pct < -0.02 else 0
        signal = "Buy" if signal_strength > 0 else "Sell" if signal_strength < 0 else "Hold"

        return {
            'signal': signal,
            'confidence': abs(signal_strength) / 3,
            'price_change_prediction': f"{price_change_pct:.2%}"
        }

    def _calculate_risk_metrics(self, prices: pd.Series) -> Dict[str, float]:
        returns = prices.pct_change().dropna()
        return {
            'volatility': returns.std() * np.sqrt(252),
            'var_95': np.percentile(returns, 5),
            'max_drawdown': (prices / prices.expanding().max() - 1).min()
        }

    def generate_summary(self, explanations: Dict) -> str:
        signals = explanations['trading_signals']
        risk = explanations['risk_metrics']

        summary = f"With steady technical indicators, {signals['signal']} is recommended at {signals['confidence']*100:.2f}% confidence. " \
                  f"The predicted price change is {signals['price_change_prediction']}. Risk is moderate, with annual volatility at {risk['volatility']:.2%}, " \
                  f"95% Value at Risk at {risk['var_95']:.2%}, and maximum drawdown at {risk['max_drawdown']:.2%}."

        return summary

class VelocityAlgo:
    def __init__(self):
        self.api_client = AlphaVantageClient(ALPHA_VANTAGE_CONFIG, ONDEMAND_CONFIG)
        self.models = self._initialize_models()
        self.scalers = self._initialize_scalers()
        self.feature_names = [
            'open', 'high', 'low', 'close', 'volume',
            'SMA_20', 'SMA_50', 'RSI', 'MACD', 'Volatility',
            'Volume_Ratio'
        ]
        self.xai = None

    def _initialize_models(self) -> Dict:
        return {
            'rf': RandomForestRegressor(n_estimators=100, random_state=42),
            'xgb': xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
        }

    def _initialize_scalers(self) -> Dict:
        return {
            'price': MinMaxScaler(),
            'features': StandardScaler()
        }

    def _prepare_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        df['SMA_20'] = df['close'].rolling(window=20).mean()
        df['SMA_50'] = df['close'].rolling(window=50).mean()
        df['RSI'] = self._calculate_rsi(df['close'])
        df['MACD'] = self._calculate_macd(df['close'])
        df['Volatility'] = df['close'].pct_change().rolling(window=20).std()
        df['Volume_Ratio'] = df['volume'] / df['volume'].rolling(window=20).mean()

        df = df.dropna().reset_index(drop=True)

        X = df[self.feature_names].values
        y = df['close'].values

        return X, y

    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        delta = prices.diff(1)
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))

    def _calculate_macd(self, prices: pd.Series) -> pd.Series:
        short_ema = prices.ewm(span=12, adjust=False).mean()
        long_ema = prices.ewm(span=26, adjust=False).mean()
        macd = short_ema - long_ema
        signal = macd.ewm(span=9, adjust=False).mean()
        return macd - signal

    def analyze_stock(self, symbol: str) -> Dict[str, Any]:
        try:
            stock_data = self.api_client.get_stock_data(symbol)

            if 'error' in stock_data:
                return stock_data

            df = pd.DataFrame(stock_data['historical_data'])
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date')

            X, y = self._prepare_features(df)

            self.models['rf'].fit(X, y)
            if 'xgb' in self.models:
                self.models['xgb'].fit(X, y)

            if self.xai is None:
                self.xai = EnhancedXAI(self.models, self.feature_names)

            predictions = self.xai.explain_prediction(X, df['close'])

            return {
                'symbol': symbol,
                'current_price': stock_data['current_price'],
                'price_change': stock_data['price_change'],
                'last_updated': df['date'].max().strftime('%Y-%m-%d'),
                'predictions': predictions
            }

        except Exception as e:
            logging.error(f"Error analyzing stock {symbol}: {str(e)}")
            return {'error': str(e)}

if __name__ == "__main__":
    algo = VelocityAlgo()

    ondemand_session = algo.api_client.ondemand_client.create_session()
    if ondemand_session:
        logging.info("OnDemand session created successfully")

    results = algo.analyze_stock("AAPL")

    if 'error' not in results:
        print(f"\nAnalysis Results for {results['symbol']}:")
        print(f"Current Price: ${results['current_price']:.2f}")
        print(f"Price Change: ${results['price_change']:.2f}")
        print(f"Last Updated: {results['last_updated']}")
        print("\nPrediction Analysis:")
        print(results['predictions']['summary'])

        print("\nTechnical Indicators Impact:")
        for indicator, impact in results['predictions']['technical_indicators'].items():
            print(f"{indicator}: {impact:.4f}")

        print("\nRisk Metrics:")
        for metric, value in results['predictions']['risk_metrics'].items():
            print(f"{metric}: {value:.2%}")
    else:
        print(f"\nError occurred during analysis: {results['error']}")

